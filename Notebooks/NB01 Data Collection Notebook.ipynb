{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Installing required libraries/ packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import shutil\n",
    "from scrapy import Selector\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['svg']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  Generative AI Statement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In compliance with the DS105W ðŸ¤– Generative AI Policy, I declare that I have used:\n",
    "- Chat GPT 3.5 and logs have been uploaded as for GenAIl project\n",
    "- I have github co-pilot installed which was mainly used to brainstorm functions and chunks or code to get started\n",
    "- Chat GPT was mainly used to trouble shoot errors, for instance:\n",
    "    - When downloading packages to trouble queries\n",
    "    - To use the type function and help identify the type for the object/ str etc\n",
    "    - To help edit functions, e.g. using it to split episode and season numbers, or to scrape different headings, such that some series have synopsises, and if not others have plots to scrape from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This task will scrape the wiki fandom page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://peaky-blinders.fandom.com'\n",
    "response = requests.get(base_url, verify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status code\n",
    "if response.status_code == 200:\n",
    "    'Everything is OK, status code:', response.status_code\n",
    "    response.text[:100]\n",
    "else:\n",
    "    print('Something went wrong, status code:', response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain all season numbers & URLs\n",
    "def get_season_links(base_url):\n",
    "    \"\"\"\n",
    "    This function returns a list of dictionaries with each season's number and URL.\n",
    "    \n",
    "    Args:\n",
    "    - base_url (str): The base URL of the Peaky Blinders wiki fandom.\n",
    "    \n",
    "    Returns:\n",
    "    - list: A list of dictionaries with each season's number and URL.\n",
    "    \"\"\"\n",
    "    response = requests.get(base_url)\n",
    "    sel = Selector(text=response.text)\n",
    "\n",
    "    # Find the element containing the list of seasons\n",
    "    ul_element = sel.xpath('//li[2]/div[2]/ul')\n",
    "    # Extract individual list items (seasons)\n",
    "    li_elements = ul_element.xpath('li[not(contains(.//span/text(), \"Cast\"))]')\n",
    "    season_list = []\n",
    "\n",
    "    # Iterate over each list item to extract season number and URL\n",
    "    for li in li_elements:\n",
    "        season_url = li.xpath('.//a/@href').get()\n",
    "        season_str = li.xpath('.//span/text()').get()\n",
    "\n",
    "        season_num = re.search(r'\\d+', season_str).group()\n",
    "\n",
    "        # Append season number and URL to the list\n",
    "        season_list.append({'season_num': season_num, 'season_url': season_url})\n",
    "\n",
    "    seasons_list = season_list[:6]\n",
    "    return seasons_list\n",
    "\n",
    "base_url = 'https://peaky-blinders.fandom.com/wiki/Peaky_Blinders_Wiki'\n",
    "# Call the function to get season numbers and URLs\n",
    "result = get_season_links(base_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode_data(season_url):\n",
    "    \"\"\"\n",
    "    This function returns a single dictionary that represents all the episodes of a season.\n",
    "\n",
    "    Args:\n",
    "    - season_url (str): The URL of the season's wiki page.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A single dictionary containing the episode number, title, air date, and URL of all episodes.\n",
    "    \"\"\"\n",
    "    response = requests.get(season_url)\n",
    "    sel = Selector(text=response.text)\n",
    "    tr_elements = sel.xpath('//tr')\n",
    "\n",
    "    episode_data = {\n",
    "        'episode_num': [],\n",
    "        'episode_title': [],\n",
    "        'episode_url': [],\n",
    "        'air_date': []\n",
    "    }\n",
    "    date_formats = ['%B %d, %Y', '%d %B %Y', '%d %B, %Y']\n",
    "    base_url = 'https://peaky-blinders.fandom.com'\n",
    "\n",
    "    for tr in tr_elements:\n",
    "        episode_num = tr.xpath('./td[3]/text()').get()\n",
    "        \n",
    "        # Check if episode title exists in both formats\n",
    "        episode_title_a = tr.xpath('./td[2]/a/b/text()').get()\n",
    "        episode_title_b = tr.xpath('./td[2]/b/a/text()').get()\n",
    "        episode_title = episode_title_a if episode_title_a else episode_title_b\n",
    "        \n",
    "        # Check if episode URL exists in both formats\n",
    "        episode_url_a = tr.xpath('./td[2]/a/@href').get()\n",
    "        episode_url_b = tr.xpath('./td[2]/b/a/@href').get()\n",
    "        episode_url = episode_url_a if episode_url_a else episode_url_b\n",
    "        \n",
    "        air_date = tr.xpath('./td[4]/text()').get()\n",
    "        \n",
    "        if episode_num and episode_title and episode_url:\n",
    "            formatted_date = None\n",
    "            for date_format in date_formats:\n",
    "                try:\n",
    "                    formatted_date = datetime.strptime(air_date.strip(), date_format).strftime('%Y-%m-%d')\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            episode_num = episode_num.strip().split('.')[1] #stripping the season no to only extract episode no.\n",
    "            episode_num = int(episode_num)  # Converts to integer\n",
    "            full_episode_url = base_url + episode_url if episode_url else None #adding base url and prefix\n",
    "\n",
    "            episode_data['episode_num'].append(episode_num)\n",
    "            episode_data['episode_title'].append(episode_title)\n",
    "            episode_data['episode_url'].append(full_episode_url)\n",
    "            episode_data['air_date'].append(formatted_date)\n",
    "\n",
    "    return episode_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an initial data frame with the seasons' links\n",
    "df = pd.DataFrame.from_dict(get_season_links(base_url))\n",
    "\n",
    "# Add the TV show name to the data frame\n",
    "df['tv_show'] = 'Peaky Blinders'\n",
    "\n",
    "# Create a new column with all episode information\n",
    "df['episode_data'] = df['season_url'].apply(get_episode_data)\n",
    "\n",
    "# Convert the episode_data column into a data frame \n",
    "# and join it with the original data frame\n",
    "df = (\n",
    "    pd.json_normalize(df['episode_data'])\n",
    "    .join(df.drop(columns='episode_data'))\n",
    "    .explode(['episode_num', 'episode_url', 'episode_title', 'air_date'])\n",
    ")\n",
    "\n",
    "# Re-order the columns\n",
    "ordered_columns = ['tv_show', 'season_num', 'season_url',\n",
    "                   'episode_num', 'episode_url', \n",
    "                   'episode_title', 'air_date']\n",
    "df = df[ordered_columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: Seasons 1-4 Episodes are named 'Episode 1, Episode 2' etc whereas Seasons 5 and 6 episodes are for instance \"Black Tuesday, or Noose\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tv_show</th>\n",
       "      <th>season_num</th>\n",
       "      <th>season_url</th>\n",
       "      <th>episode_num</th>\n",
       "      <th>episode_url</th>\n",
       "      <th>episode_title</th>\n",
       "      <th>air_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peaky Blinders</td>\n",
       "      <td>1</td>\n",
       "      <td>https://peaky-blinders.fandom.com/wiki/Series_1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://peaky-blinders.fandom.com/wiki/Episode...</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>2013-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peaky Blinders</td>\n",
       "      <td>1</td>\n",
       "      <td>https://peaky-blinders.fandom.com/wiki/Series_1</td>\n",
       "      <td>2</td>\n",
       "      <td>https://peaky-blinders.fandom.com/wiki/Episode...</td>\n",
       "      <td>Episode 2</td>\n",
       "      <td>2013-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peaky Blinders</td>\n",
       "      <td>1</td>\n",
       "      <td>https://peaky-blinders.fandom.com/wiki/Series_1</td>\n",
       "      <td>3</td>\n",
       "      <td>https://peaky-blinders.fandom.com/wiki/Episode...</td>\n",
       "      <td>Episode 3</td>\n",
       "      <td>2013-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peaky Blinders</td>\n",
       "      <td>1</td>\n",
       "      <td>https://peaky-blinders.fandom.com/wiki/Series_1</td>\n",
       "      <td>4</td>\n",
       "      <td>https://peaky-blinders.fandom.com/wiki/Episode...</td>\n",
       "      <td>Episode 4</td>\n",
       "      <td>2013-10-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peaky Blinders</td>\n",
       "      <td>1</td>\n",
       "      <td>https://peaky-blinders.fandom.com/wiki/Series_1</td>\n",
       "      <td>5</td>\n",
       "      <td>https://peaky-blinders.fandom.com/wiki/Episode...</td>\n",
       "      <td>Episode 5</td>\n",
       "      <td>2013-10-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tv_show season_num                                       season_url  \\\n",
       "0  Peaky Blinders          1  https://peaky-blinders.fandom.com/wiki/Series_1   \n",
       "0  Peaky Blinders          1  https://peaky-blinders.fandom.com/wiki/Series_1   \n",
       "0  Peaky Blinders          1  https://peaky-blinders.fandom.com/wiki/Series_1   \n",
       "0  Peaky Blinders          1  https://peaky-blinders.fandom.com/wiki/Series_1   \n",
       "0  Peaky Blinders          1  https://peaky-blinders.fandom.com/wiki/Series_1   \n",
       "\n",
       "  episode_num                                        episode_url  \\\n",
       "0           1  https://peaky-blinders.fandom.com/wiki/Episode...   \n",
       "0           2  https://peaky-blinders.fandom.com/wiki/Episode...   \n",
       "0           3  https://peaky-blinders.fandom.com/wiki/Episode...   \n",
       "0           4  https://peaky-blinders.fandom.com/wiki/Episode...   \n",
       "0           5  https://peaky-blinders.fandom.com/wiki/Episode...   \n",
       "\n",
       "  episode_title    air_date  \n",
       "0     Episode 1  2013-09-12  \n",
       "0     Episode 2  2013-09-19  \n",
       "0     Episode 3  2013-09-26  \n",
       "0     Episode 4  2013-10-03  \n",
       "0     Episode 5  2013-10-10  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving DataFrame to CSV file\n",
    "df.to_csv('../data/peaky_blinders_episodes.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_peaky_blinders_synopses(episode_url):\n",
    "    \"\"\"\n",
    "    Retrieves synopsis data for a given episode.\n",
    "    Args:\n",
    "    - episode_url (str): The URL of the episode's wiki page.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing the synopsis data for the episode, \n",
    "            with keys 'paragraph_id', 'link_title', and 'link_url' (or None if not found).\n",
    "    \"\"\"\n",
    "    response = requests.get(episode_url)\n",
    "    sel = Selector(text=response.text)\n",
    "\n",
    "    # Find the section containing the synopsis\n",
    "    summary_heading = sel.xpath('//span[@id=\"Summary\"]') or sel.xpath('//span[@id=\"Plot\"]')\n",
    "    cast_heading = sel.xpath('//span[@id=\"Cast\"]')\n",
    "\n",
    "    # If neither 'Summary' nor 'Plot' heading found, return None\n",
    "    if not summary_heading or not cast_heading:\n",
    "        print(\"Error: 'Summary' or 'Plot' heading not found.\")\n",
    "        return None\n",
    "\n",
    "    # Extracting summary paragraphs\n",
    "    summary_paragraphs_filtered = [\n",
    "        paragraph \n",
    "        for paragraph in summary_heading.xpath('./ancestor::h2/following-sibling::p')\n",
    "        if paragraph.xpath('.//span[@id=\"Cast\"]/ancestor::h2') != cast_heading.xpath('./ancestor::h2')\n",
    "    ]\n",
    "\n",
    "    # Extracting link titles and URLs\n",
    "    synopsis_data = {\n",
    "        'paragraph_id': [],\n",
    "        'link_title': [],\n",
    "        'link_url': [],\n",
    "    }\n",
    "    base_url = 'https://peaky-blinders.fandom.com'\n",
    "    for paragraph_id, paragraph in enumerate(summary_paragraphs_filtered, start=1):\n",
    "        link_titles = paragraph.xpath('.//a[contains(@href, \"/wiki/\")]/text()').extract()\n",
    "        link_urls = paragraph.xpath('.//a[contains(@href, \"/wiki/\")]/@href').extract()\n",
    "        synopsis_data['paragraph_id'].extend([paragraph_id] * len(link_titles))\n",
    "        full_episode_urls = [base_url + link_url if link_url else None for link_url in link_urls]\n",
    "        synopsis_data['link_title'].extend(link_titles)\n",
    "        synopsis_data['link_url'].extend(full_episode_urls)\n",
    "\n",
    "    return synopsis_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season_links(base_url):\n",
    "    \"\"\"\n",
    "    This function returns a dictionary with each season's URL and number as key-value pairs.\n",
    "    Args:\n",
    "    - base_url (str): The base URL of the Peaky Blinders wiki fandom.\n",
    "    Returns:\n",
    "    - dict: A dictionary with each season's URL and number.\n",
    "    \"\"\"\n",
    "    response = requests.get(base_url)\n",
    "    sel = Selector(text=response.text)\n",
    "\n",
    "    # Find the element containing the list of seasons\n",
    "    ul_element = sel.xpath('//li[2]/div[2]/ul')\n",
    "    # Extract individual list items (seasons)\n",
    "    li_elements = ul_element.xpath('li[not(contains(.//span/text(), \"Cast\"))]')\n",
    "    \n",
    "    # Use list comprehension to create the dictionary\n",
    "    season_dict = {\n",
    "        li.xpath('.//a/@href').get(): {'season_num': re.search(r'\\d+', li.xpath('.//span/text()').get()).group()}\n",
    "        for li in li_elements\n",
    "    }\n",
    "    return season_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/txlxdw296xv2ybrrhzwrv8j40000gn/T/ipykernel_96556/2508302616.py:56: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tv_show</th>\n",
       "      <th>season_num</th>\n",
       "      <th>episode_num</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>link_title</th>\n",
       "      <th>link_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peaky Blinders</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Shelbys</td>\n",
       "      <td>https://peaky-blinders.fandom.com/wiki/Shelby_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peaky Blinders</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Arthur Shelby</td>\n",
       "      <td>https://peaky-blinders.fandom.com/wiki/Arthur_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peaky Blinders</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>church</td>\n",
       "      <td>https://peaky-blinders.fandom.com/wiki/Catholi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peaky Blinders</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Polly Gray</td>\n",
       "      <td>https://peaky-blinders.fandom.com/wiki/Polly_Gray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peaky Blinders</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Grace Burgess</td>\n",
       "      <td>https://peaky-blinders.fandom.com/wiki/Grace_S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tv_show season_num  episode_num  paragraph_id     link_title  \\\n",
       "0  Peaky Blinders          1            1             1        Shelbys   \n",
       "1  Peaky Blinders          1            1             1  Arthur Shelby   \n",
       "2  Peaky Blinders          1            1             2         church   \n",
       "3  Peaky Blinders          1            1             2     Polly Gray   \n",
       "4  Peaky Blinders          1            1             3  Grace Burgess   \n",
       "\n",
       "                                            link_url  \n",
       "0  https://peaky-blinders.fandom.com/wiki/Shelby_...  \n",
       "1  https://peaky-blinders.fandom.com/wiki/Arthur_...  \n",
       "2  https://peaky-blinders.fandom.com/wiki/Catholi...  \n",
       "3  https://peaky-blinders.fandom.com/wiki/Polly_Gray  \n",
       "4  https://peaky-blinders.fandom.com/wiki/Grace_S...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_episode_data(season_url):\n",
    "    response = requests.get(season_url)\n",
    "    sel = Selector(text=response.text)\n",
    "    tr_elements = sel.xpath('//tr')\n",
    "\n",
    "    episode_data = []\n",
    "    base_url = 'https://peaky-blinders.fandom.com'\n",
    "\n",
    "    for tr in tr_elements:\n",
    "        episode_num = tr.xpath('./td[3]/text()').get()\n",
    "        \n",
    "        # Check if episode URL exists in both formats\n",
    "        episode_url_a = tr.xpath('./td[2]/a/@href').get()\n",
    "        episode_url_b = tr.xpath('./td[2]/b/a/@href').get()\n",
    "        episode_url = episode_url_a if episode_url_a else episode_url_b\n",
    "        \n",
    "        if episode_num and episode_url:\n",
    "            episode_num = episode_num.strip().split('.')[1]\n",
    "            episode_num = int(episode_num)  # Convert to integer\n",
    "            full_episode_url = base_url + episode_url if episode_url else None\n",
    "            synopsis_data = scrape_peaky_blinders_synopses(full_episode_url)\n",
    "            if synopsis_data:\n",
    "                # Pad the lists to ensure they are of equal length\n",
    "                max_length = max(len(synopsis_data['paragraph_id']), len(synopsis_data['link_title']), len(synopsis_data['link_url']))\n",
    "                synopsis_data['paragraph_id'] += [None] * (max_length - len(synopsis_data['paragraph_id']))\n",
    "                synopsis_data['link_title'] += [None] * (max_length - len(synopsis_data['link_title']))\n",
    "                synopsis_data['link_url'] += [None] * (max_length - len(synopsis_data['link_url']))\n",
    "                # Create a DataFrame from the dictionary\n",
    "                synopsis_data_df = pd.DataFrame(synopsis_data)\n",
    "                synopsis_data_df['tv_show'] = 'Peaky Blinders'\n",
    "                synopsis_data_df['season_num'] = season_url.split('_')[-1]\n",
    "                synopsis_data_df['episode_num'] = episode_num\n",
    "                episode_data.append(synopsis_data_df)\n",
    "\n",
    "    if episode_data:\n",
    "        return pd.concat(episode_data)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Get the base URL\n",
    "base_url = 'https://peaky-blinders.fandom.com/wiki/Peaky_Blinders_Wiki'\n",
    "\n",
    "season_dict = get_season_links(base_url)\n",
    "\n",
    "all_episode_data = [] # List to store all episode data\n",
    "for season_url, season_info in season_dict.items():\n",
    "    episode_data = get_episode_data(season_url)\n",
    "    if episode_data is not None:\n",
    "        all_episode_data.append(episode_data)\n",
    "\n",
    "\n",
    "# Concatenate all episode data into a single DataFrame\n",
    "final_episode_data = pd.concat(all_episode_data)\n",
    "final_episode_data = final_episode_data[['tv_show', 'season_num', 'episode_num', 'paragraph_id', 'link_title', 'link_url']] #Reordering columns\n",
    "\n",
    "final_episode_data['paragraph_id'] = final_episode_data['paragraph_id'].fillna(1)\n",
    "\n",
    "final_episode_data['paragraph_id'] = final_episode_data['paragraph_id'].astype(int)\n",
    "final_episode_data.to_csv('../data/peaky_blinders_synopsis.csv', index=False)\n",
    "display(final_episode_data.head()) #head of the dataframe\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
